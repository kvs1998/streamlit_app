import os
import sys
import logging
import re # Still useful for a slightly better semicolon check

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# --- Helper Function for Semicolon ---

def add_trailing_semicolon(sql_content):
    """
    Adds a trailing semicolon to SQL content if it doesn't already end with one,
    after stripping trailing whitespace.
    """
    stripped_content = sql_content.rstrip()
    if not stripped_content:
        return "" # Handle empty or all-whitespace content

    # Check the last actual character
    if stripped_content[-1] != ';':
        return stripped_content + ';'
    else:
        return stripped_content # Already ends with a semicolon


# --- Main Combination Function ---

def combine_sql_files_in_directories(base_directory, output_filename="combined.sql"):
    """
    Combines all .sql files found in each direct subdirectory of the base_directory
    into a single output_filename.
    - If any SQL file in a directory cannot be read, the entire merge for that directory is discarded.
    - Each file content is checked for and possibly appended with a trailing semicolon.
    """
    logger.info(f"--- Starting SQL file combination process in: '{base_directory}' ---\n")

    if not os.path.isdir(base_directory):
        logger.error(f"Base directory '{base_directory}' not found. Please provide a valid path.", file=sys.stderr)
        return

    processed_directories_summary = []

    for item_name in os.listdir(base_directory):
        item_path = os.path.join(base_directory, item_name)

        if os.path.isdir(item_path):
            logger.info(f"--- Processing directory: '{item_path}' ---")
            
            output_file_path = os.path.join(item_path, output_filename)
            all_sql_content = []
            
            sql_files_to_process = []
            errored_files_in_dir = []
            
            # First pass: Identify SQL files and filter out the output file itself
            for file_name in os.listdir(item_path):
                if file_name.endswith(".sql") and file_name != output_filename:
                    sql_files_to_process.append(file_name)

            if not sql_files_to_process:
                logger.info(f"  No .sql files (excluding '{output_filename}') found in '{item_path}'. Skipping.\n")
                processed_directories_summary.append({
                    "directory": item_path,
                    "status": "Skipped",
                    "reason": "No SQL files found"
                })
                continue # Move to the next directory

            logger.info(f"  Found {len(sql_files_to_process)} .sql files to potentially combine.")
            
            # Second pass: Read content and handle errors/modifications
            for file_name in sql_files_to_process:
                sql_file_path = os.path.join(item_path, file_name)
                
                try:
                    with open(sql_file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                        # --- SQL Standard Checks & Modifications ---
                        # 1. Add trailing semicolon
                        modified_content = add_trailing_semicolon(content)
                        if modified_content != content:
                            logger.info(f"    - Added trailing semicolon to '{file_name}'.")

                        # Add content and a separator for readability
                        all_sql_content.append(f"-- --- Start of {file_name} ---")
                        all_sql_content.append(modified_content.strip()) # strip to avoid leading/trailing newlines from original file
                        all_sql_content.append(f"-- --- End of {file_name} ---\n\n") # Double newline for separation
                        logger.info(f"    - Processed '{file_name}'.")

                except Exception as e:
                    errored_files_in_dir.append(file_name)
                    logger.error(f"  Error reading file '{sql_file_path}': {e}", file=sys.stderr)
                    # Continue to next file to collect all errors for the summary

            if errored_files_in_dir:
                logger.warning(f"\n  Errors detected during file reads in '{item_path}'. Discarding merge.")
                logger.warning(f"  Errored files: {', '.join(errored_files_in_dir)}\n")
                processed_directories_summary.append({
                    "directory": item_path,
                    "status": "Failed (Discarded)",
                    "reason": "Errors reading source SQL files",
                    "errored_files": errored_files_in_dir
                })
                continue # Move to the next directory
            
            if not all_sql_content: # This would happen if all files had read errors
                logger.warning(f"\n  No valid SQL content to combine from '{item_path}'. Discarding merge.\n")
                processed_directories_summary.append({
                    "directory": item_path,
                    "status": "Failed (No Valid Content)",
                    "reason": "No SQL files passed checks or were found"
                })
                continue

            try:
                with open(output_file_path, 'w', encoding='utf-8') as outfile:
                    outfile.write("\n".join(all_sql_content).strip() + "\n")
                
                # Calculate successfully combined files
                success_count = len(sql_files_to_process) - len(errored_files_in_dir)
                logger.info(f"  Successfully combined {success_count} valid SQL files into: '{output_file_path}'\n")
                processed_directories_summary.append({
                    "directory": item_path,
                    "status": "Success",
                    "files_combined": success_count,
                    "output_file": output_file_path
                })
            except Exception as e:
                logger.error(f"  Error writing combined file '{output_file_path}': {e}", file=sys.stderr)
                processed_directories_summary.append({
                    "directory": item_path,
                    "status": "Failed (Write Error)",
                    "reason": f"Error writing combined file: {e}"
                })
        else:
            # Skip non-directory items in the base_directory
            logger.info(f"--- Skipping non-directory item: '{item_path}' ---\n")

    logger.info("\n--- SQL file combination process finished. ---")
    logger.info("\n--- Summary ---")
    for entry in processed_directories_summary:
        status = entry['status']
        dir_name = os.path.basename(entry['directory'])
        if status == "Success":
            logger.info(f"  [SUCCESS] Directory '{dir_name}': Combined {entry.get('files_combined', 'N/A')} files into '{os.path.basename(entry['output_file'])}'.")
        elif status == "Skipped":
            logger.warning(f"  [SKIPPED] Directory '{dir_name}': {entry['reason']}.")
        elif status.startswith("Failed"):
            error_details = ""
            if 'errored_files' in entry:
                error_details = f" due to errors in files: {', '.join(entry['errored_files'])}"
            elif 'reason' in entry:
                error_details = f". Reason: {entry['reason']}."
            logger.error(f"  [{status.upper()}] Directory '{dir_name}': Discarded merge{error_details}.")
    logger.info("\n-----------------")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Combine SQL files in subdirectories, enforcing trailing semicolons.")
    parser.add_argument("base_directory", nargs='?', 
                        help="The base directory containing subdirectories with SQL files. Defaults to Eldrich_script in the script's parent dir if not provided.",
                        default=None)
    parser.add_argument("--output_name", default="combined_queries.sql",
                        help="The name of the combined output file in each subdirectory. Default: combined_queries.sql")
    
    args = parser.parse_args()

    base_script_directory = args.base_directory
    if base_script_directory is None:
        base_script_directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), "Eldrich_script")
        logger.info(f"No base directory path provided via arguments. Using default: '{base_script_directory}'")

    combine_sql_files_in_directories(
        base_script_directory, 
        args.output_name
    )
