# tabs/dt_health_tab.py (Modified to use dynamic filters, with correct local filtering)
import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta

# --- Helper functions (from previous code) ---
def format_seconds_to_readable(seconds_series, format_type):
    if not isinstance(seconds_series, pd.Series):
        seconds_series = pd.Series([seconds_series])
    numeric_series = pd.to_numeric(seconds_series, errors='coerce')
    if numeric_series.empty or pd.isna(numeric_series).all():
        return pd.Series(["N/A"] * len(numeric_series), index=numeric_series.index)
    def format_single_second(s, f_type):
        if pd.isna(s): return "N/A"
        s = float(s)
        if s == 0: return "0s"
        if f_type == "seconds": return f"{s:.1f}s"
        elif f_type == "minutes": return f"{(s / 60):.1f}m"
        elif f_type == "hours": return f"{(s / 3600):.1f}h"
        elif f_type == "days": return f"{(s / 86400):.1f}d"
        elif f_type == "mixed":
            days = int(s // 86400); s_remaining = s % 86400
            hours = int(s_remaining // 3600); s_remaining = s_remaining % 3600
            minutes = int(s_remaining // 60); seconds = s_remaining % 60
            parts = []
            if days > 0: parts.append(f"{days}d")
            if hours > 0: parts.append(f"{hours}h")
            if minutes > 0: parts.append(f"{minutes}m")
            if seconds > 0.1 and (not parts or seconds >= 1): parts.append(f"{seconds:.1f}s")
            return " ".join(parts) if parts else "0s"
        return str(s)
    return numeric_series.apply(lambda x: format_single_second(x, f_type=format_type))

# --- Data Fetching Functions ---

@st.cache_data(ttl=(12*60*60))
def fetch_driver_execution_history_summary():
    session = st.session_state.get_snowflake_session()
    AUDIT_LOG_TABLE_FQDN = "YOUR_DB.YOUR_SCHEMA.T_DT_COLLECTION_AUDIT_LOG"
    query = f"""
    SELECT
        DRIVER_RUN_UUID, RUN_STATUS, RUN_START_TIME, RUN_END_TIME,
        TOTAL_DURATION_SEC, TOTAL_TABLES_FOUND, TOTAL_JOBS_LAUNCHED,
        TOTAL_ASYNC_JOBS_SUCCEEDED, TOTAL_ASYNC_JOBS_FAILED,
        MESSAGE AS RUN_MESSAGE, TIMEZONE
    FROM {AUDIT_LOG_TABLE_FQDN}
    WHERE RUN_START_TIME >= DATEADD(day, -30, CURRENT_TIMESTAMP())
    ORDER BY RUN_START_TIME DESC
    """
    df = session.sql(query).to_pandas()
    if not df.empty:
        df['RUN_START_TIME'] = pd.to_datetime(df['RUN_START_TIME'])
        df['RUN_END_TIME'] = pd.to_datetime(df['RUN_END_TIME'])
    return df

@st.cache_data(ttl=(5*60))
def fetch_dt_tracking_data():
    session = st.session_state.get_snowflake_session()
    TRACKING_TABLE_FQDN = "YOUR_DB.YOUR_SCHEMA.T_DYNAMIC_TABLE_TRACKING"
    METADATA_SNAPSHOT_TABLE_FQDN = "YOUR_DB.YOUR_SCHEMA.T_DYNAMIC_TABLE_METADATA_LATEST_SNAPSHOT"

    query = f"""
    SELECT
        t.QUALIFIED_NAME,
        t.DATABASE_NAME,
        t.SCHEMA_NAME,
        t.TABLE_NAME,
        t.DOMAIN_NAME,
        t.SUB_DOMAIN_NAME,
        t.IS_ACTIVE,
        t.TRACK_REFRESH_HISTORY,
        t.LAST_REFRESH_HISTORY_COLLECTION_TIMESTAMP,
        t.LAST_REFRESH_HISTORY_COLLECTION_STATUS,
        t.LAST_REFRESH_HISTORY_COLLECTION_MESSAGE,
        t.TRACK_METADATA_SNAPSHOT,
        t.LAST_METADATA_COLLECTION_TIMESTAMP,
        t.LAST_METADATA_COLLECTION_STATUS,
        t.LAST_METADATA_COLLECTION_MESSAGE,
        ms.LATEST_DATA_TIMESTAMP,
        ms.MEAN_LAG_SEC,
        ms.MAXIMUM_LAG_SEC,
        ms.TARGET_LAG_SEC,
        t.UPDATED_AT
    FROM
        {TRACKING_TABLE_FQDN} AS t
    LEFT JOIN
        {METADATA_SNAPSHOT_TABLE_FQDN} AS ms
    ON
        t.QUALIFIED_NAME = ms.QUALIFIED_NAME
    ORDER BY
        t.QUALIFIED_NAME
    """
    df = session.sql(query).to_pandas()
    if not df.empty:
        df['LAST_REFRESH_HISTORY_COLLECTION_TIMESTAMP'] = pd.to_datetime(df['LAST_REFRESH_HISTORY_COLLECTION_TIMESTAMP'])
        df['LAST_METADATA_COLLECTION_TIMESTAMP'] = pd.to_datetime(df['LAST_METADATA_COLLECTION_TIMESTAMP'])
        df['LATEST_DATA_TIMESTAMP'] = pd.to_datetime(df['LATEST_DATA_TIMESTAMP'])
        df['UPDATED_AT'] = pd.to_datetime(df['UPDATED_AT'])
    return df


# --- Helper to manage widget state persistence for local filters (re-using helpers from filter_canvas) ---
def persist_local_widget_state(key_prefix):
    temp_key = f"_{key_prefix}"
    perm_key = key_prefix
    if temp_key in st.session_state:
        st.session_state[perm_key] = st.session_state[temp_key]

def load_local_widget_state(key_prefix, default_value):
    perm_key = key_prefix
    temp_key = f"_{key_prefix}"
    if perm_key not in st.session_state:
        st.session_state[perm_key] = default_value
    st.session_state[temp_key] = st.session_state[perm_key]
    return st.session_state[perm_key]


# --- Filter Definitions Map for Local Filters (using the same structure as global) ---
# NOTE: This defines the filters specific to THIS TAB.
LOCAL_FILTER_DEFINITIONS = [
    {
        'id': 'domain_name',
        'label': "Domain Name:",
        'column_name': 'DOMAIN_NAME',
        'widget_type': 'selectbox',
        'default_value': 'All'
    },
    {
        'id': 'sub_domain_name',
        'label': "Sub Domain Name:",
        'column_name': 'SUB_DOMAIN_NAME',
        'widget_type': 'selectbox',
        'default_value': 'All',
        'depends_on': 'domain_name'
    },
    {
        'id': 'database',
        'label': "Database:",
        'column_name': 'DATABASE_NAME',
        'widget_type': 'selectbox',
        'default_value': 'All',
        'depends_on': 'sub_domain_name'
    },
    {
        'id': 'schema',
        'label': "Schema:",
        'column_name': 'SCHEMA_NAME',
        'widget_type': 'selectbox',
        'default_value': 'All',
        'depends_on': 'database'
    },
    {
        'id': 'table_name',
        'label': "Table(s):",
        'column_name': 'TABLE_NAME',
        'widget_type': 'multiselect',
        'default_value': ['All'],
        'depends_on': 'schema'
    },
    {
        'id': 'scheduling_state',
        'label': "Scheduling State(s):",
        'column_name': 'SCHEDULING_STATE_STATUS',
        'widget_type': 'multiselect',
        'default_value': ['All']
    },
    {
        'id': 'target_lag',
        'label': "Target Lag (seconds):",
        'column_name': 'TARGET_LAG_SEC_FMT', # Formatted for display
        'original_column_name': 'TARGET_LAG_SEC', # To filter by original numeric value
        'widget_type': 'multiselect',
        'default_value': ['All']
    }
    # Is Active is NOT included in LOCAL filters as it's assumed to be handled globally only.
]

# Separate filter definition for the independent radio button (Display Lag Times In)
LOCAL_RADIO_FILTER_DEFINITION = {
    'id': 'display_lag_times_in', # Note: This ID needs to be unique for this tab
    'label': "Display Lag Times In:",
    'options': ["mixed", "seconds", "minutes", "hours", "days"],
    'default_value': 'mixed'
}


def render_dynamic_filters_local(all_data_for_options: pd.DataFrame, filter_prefix: str = "dt_health_tab_"):
    """
    Renders a set of interdependent filter widgets for LOCAL use within a tab.
    Applies "parent takes priority" reset logic.
    
    Args:
        all_data_for_options (pd.DataFrame): The full DataFrame of data to derive filter options from.
        filter_prefix (str): Prefix for session state keys (e.g., 'dt_health_tab_').
    
    Returns:
        dict: The current selections from all local filters.
    """
    
    # --- Initialize Column Layouts ---
    # Row 1: Domain Name, Sub Domain Name, Database, Schema
    cols_row1 = st.columns(4) 
    # Row 2: Table(s), Scheduling State(s), Target Lag (seconds), Display Lag Times In
    cols_row2 = st.columns(4) 
    # Note: 'is_active' filter is not explicitly in this local layout, assuming it's only global.

    # Map filter IDs to specific Streamlit column objects based on desired layout
    col_map = {
        'domain_name': cols_row1[0],
        'sub_domain_name': cols_row1[1],
        'database': cols_row1[2],
        'schema': cols_row1[3],

        'table_name': cols_row2[0],
        'scheduling_state': cols_row2[1],
        'target_lag': cols_row2[2],
        'display_lag_times_in': cols_row2[3] # Display Lag Times In (radio button)
    }

    # This DataFrame will be progressively filtered as we determine options for cascading widgets.
    # It starts with the complete, unfiltered data for options (within this function's scope).
    filtered_df_for_options_cascade = all_data_for_options.copy() 

    # Loop through filter definitions in their specified order (important for dependencies)
    # This determines the logical order in which options are derived and widgets' stored values are validated/reset.
    # (Domain -> Sub Domain -> Database -> Schema -> Table)
    for f_def in LOCAL_FILTER_DEFINITIONS: # Iterate through defined local filters
        current_filter_session_key = f"{filter_prefix}{f_def['id']}"
        
        # --- 1. Determine available options for THIS filter ---
        options_from_df_for_current_filter = all_data_for_options.copy() # Start fresh for option derivation
        
        # Apply parent filters that have already been processed in the *logical cascade*
        # (even if they are rendered later visually)
        if 'depends_on' in f_def:
            parent_id = f_def['depends_on']
            parent_col_name = next(fd_p['column_name'] for fd_p in LOCAL_FILTER_DEFINITIONS if fd_p['id'] == parent_id)
            # Use the already stored/updated session state value of the parent for filtering options
            parent_selection_value = st.session_state.get(f"{filter_prefix}{parent_id}") 
            
            if parent_selection_value and parent_selection_value != 'All':
                if isinstance(parent_selection_value, list) and 'All' not in parent_selection_value:
                     options_from_df_for_current_filter = options_from_df_for_current_filter[options_from_df_for_current_filter[parent_col_name].isin(parent_selection_value)]
                else: # Single selectbox parent
                     options_from_df_for_current_filter = options_from_df_for_current_filter[options_from_df_for_current_filter[parent_col_name] == parent_selection_value]

        # Get the unique options list for the current filter's column
        options_list_for_widget = []
        if 'options_override' in f_def:
            options_list_for_widget = f_def['options_override']
        else:
            options_from_df = options_from_df_for_current_filter[f_def['column_name']].dropna().unique().tolist()
            options_list_for_widget = ['All'] + sorted(options_from_df)
        
        # --- 2. Determine the initial selection for the widget (applying "parent takes priority" reset) ---
        # Load the current stored value from session state
        current_stored_value = load_local_widget_state(f_def['id'], f_def['default_value'])

        # Reset logic: If current_stored_value is NOT in the newly determined `options_list_for_widget`,
        # reset it to the default. This is the core "parent takes priority" logic.
        
        if f_def['widget_type'] == 'selectbox':
            if current_stored_value not in options_list_for_widget:
                current_stored_value = f_def['default_value']
                # Crucial: Update session state for the reset value immediately
                st.session_state[current_filter_session_key] = current_stored_value
            
            widget_index = options_list_for_widget.index(current_stored_value)
            
            with col_map[f_def['id']]: # Render in its mapped column
                selected_value_from_widget = st.selectbox(
                    f_def['label'],
                    options=options_list_for_widget,
                    key=f"_{current_filter_session_key}", # Dummy key for persistence helper
                    index=widget_index,
                    on_change=persist_local_widget_state, args=(f_def['id'],) # on_change updates actual key
                )

        elif f_def['widget_type'] == 'multiselect':
            valid_selections = [v for v in current_stored_value if v in options_list_for_widget]
            if not valid_selections and f_def['default_value'] == ['All'] and 'All' in options_list_for_widget:
                valid_selections = ['All']
            elif not valid_selections: # If no valid selections and 'All' not applicable or desired
                valid_selections = []
            
            # Update session state with the validated list
            st.session_state[current_filter_session_key] = valid_selections

            with col_map[f_def['id']]: # Render in its mapped column
                selected_value_from_widget = st.multiselect(
                    f_def['label'],
                    options=options_list_for_widget,
                    key=f"_{current_filter_session_key}", # Dummy key
                    default=valid_selections, # Multiselect uses default
                    on_change=persist_local_widget_state, args=(f_def['id'],)
                )
    
    # --- Render the independent radio button (Display Lag Times In) ---
    radio_f_def = LOCAL_RADIO_FILTER_DEFINITION
    # Load its stored value and ensure it's valid
    current_radio_value = load_local_widget_state(radio_f_def['id'], radio_f_def['default_value'])
    radio_options_list = radio_f_def['options']
    if current_radio_value not in radio_options_list:
        current_radio_value = radio_f_def['default_value']
        st.session_state[radio_f_def['id']] = current_radio_value
    radio_index = radio_options_list.index(current_radio_value)

    with col_map[radio_f_def['id']]:
        st.radio(
            radio_f_def['label'],
            options=radio_options_list,
            key=f"_{radio_f_def['id']}", # Dummy key
            index=radio_index,
            horizontal=True,
            on_change=persist_local_widget_state, args=(radio_f_def['id'],)
        )

    # Return the collected selections (from the permanent session state keys)
    # This dictionary aggregates the current state of all local filters
    final_filters_state = {}
    for f_def in LOCAL_FILTER_DEFINITIONS:
        final_filters_state[f_def['id']] = st.session_state[f"{filter_prefix}{f_def['id']}"]
    final_filters_state[LOCAL_RADIO_FILTER_DEFINITION['id']] = st.session_state[LOCAL_RADIO_FILTER_DEFINITION['id']]
    
    return final_filters_state # Returns the dict of active local filters


def render_dt_health_tab():
    st.header("Dynamic Table Health Dashboard")
    st.write("Overview of driver execution, collection status, and detailed table health.")

    # --- 1. Fetch Data ---
    driver_history_df = fetch_driver_execution_history_summary()
    all_tracking_data_df = fetch_dt_tracking_data()

    if all_tracking_data_df.empty:
        st.info("No data available from tracking tables. Please check data sources.", icon="ℹ️")
        return
    
    # --- Global Filters (from app_driver.py/filter_canvas.py) ---
    # Apply global filters first to `all_tracking_data_df`
    globally_filtered_data = all_tracking_data_df.copy()

    # Ensure global filter states are initialized with a default fallback if filter_canvas wasn't visited
    # These reads MUST match the keys used in filter_canvas.py
    global_domain_name_filter = st.session_state.get('global_domain_name', 'All')
    global_sub_domain_name_filter = st.session_state.get('global_sub_domain_name', 'All')
    global_db_filter = st.session_state.get('global_db_filter', 'All')
    global_schema_filter = st.session_state.get('global_schema_filter', 'All')
    global_table_filter = st.session_state.get('global_table_filter', ['All'])
    global_scheduling_state_filter = st.session_state.get('global_scheduling_state_filter', ['All'])
    global_target_lag_filter = st.session_state.get('global_target_lag', ['All'])
    global_is_active_filter = st.session_state.get('global_is_active_filter', 'All')
    global_display_lag_times_in = st.session_state.get('display_lag_times_in', 'mixed') # Radio button is also global


    if global_domain_name_filter != 'All':
        globally_filtered_data = globally_filtered_data[globally_filtered_data['DOMAIN_NAME'] == global_domain_name_filter]
    if global_sub_domain_name_filter != 'All':
        globally_filtered_data = globally_filtered_data[globally_filtered_data['SUB_DOMAIN_NAME'] == global_sub_domain_name_filter]
    if global_db_filter != 'All':
        globally_filtered_data = globally_filtered_data[globally_filtered_data['DATABASE_NAME'] == global_db_filter]
    if global_schema_filter != 'All':
        globally_filtered_data = globally_filtered_data[globally_filtered_data['SCHEMA_NAME'] == global_schema_filter]
    if 'All' not in global_table_filter:
        globally_filtered_data = globally_filtered_data[globally_filtered_data['TABLE_NAME'].isin(global_table_filter)]
    if 'All' not in global_scheduling_state_filter:
        globally_filtered_data = globally_filtered_data[globally_filtered_data['LAST_REFRESH_HISTORY_COLLECTION_STATUS'].isin(global_scheduling_state_filter)]
    if 'All' not in global_target_lag_filter:
        global_target_lag_values_numeric = [int(s.replace('s', '')) for s in global_target_lag_filter]
        globally_filtered_data = globally_filtered_data[globally_filtered_data['TARGET_LAG_SEC'].isin(global_target_lag_values_numeric)]
    if global_is_active_filter != 'All':
        globally_filtered_data = globally_filtered_data[globally_filtered_data['IS_ACTIVE'] == global_is_active_filter]
    
    
    if globally_filtered_data.empty:
        st.info("No data available based on the current Global Filter Canvas selections. Please adjust your global filters.", icon="ℹ️")
        return


    # --- Local Filters (Second Level of Filtering) for this tab's specific UI ---
    st.markdown("---")
    st.subheader("Apply Filters for DT Health (Local)")

    # Initialize local filter states here (using a distinct prefix like 'dt_health_tab_')
    # These are used to populate widgets and filter further.
    if 'dt_health_tab_domain_name' not in st.session_state: st.session_state.dt_health_tab_domain_name = 'All'
    if 'dt_health_tab_sub_domain_name' not in st.session_state: st.session_state.dt_health_tab_sub_domain_name = 'All'
    if 'dt_health_tab_db_filter' not in st.session_state: st.session_state.dt_health_tab_db_filter = 'All'
    if 'dt_health_tab_schema_filter' not in st.session_state: st.session_state.dt_health_tab_schema_filter = 'All'
    if 'dt_health_tab_table_filter' not in st.session_state: st.session_state.dt_health_tab_table_filter = ['All']
    if 'dt_health_tab_scheduling_state_filter' not in st.session_state: st.session_state.dt_health_tab_scheduling_state_filter = ['All']
    if 'dt_health_tab_target_lag' not in st.session_state: st.session_state.dt_health_tab_target_lag = ['All']
    if 'dt_health_tab_display_lag_times_in' not in st.session_state: st.session_state.dt_health_tab_display_lag_times_in = 'mixed'


    # Call render_dynamic_filters (same function) for local filters
    # Pass the GLOBALLY filtered data as the source for options for these local widgets.
    # The filter_prefix is 'dt_health_tab_' to ensure unique session state keys.
    current_local_filters_state = render_dynamic_filters(globally_filtered_data, filter_prefix="dt_health_tab_")
    
    # Extract specific local filter values after rendering to apply to DataFrame
    local_domain_name_filter = current_local_filters_state['domain_name']
    local_sub_domain_name_filter = current_local_filters_state['sub_domain_name']
    local_db_filter = current_local_filters_state['database']
    local_schema_filter = current_local_filters_state['schema']
    local_table_filter = current_local_filters_state['table_name']
    local_scheduling_state_filter = current_local_filters_state['scheduling_state']
    local_target_lag_filter = current_local_filters_state['target_lag']
    local_display_lag_times_in = current_local_filters_state['display_lag_times_in']


    # --- Apply LOCAL filters to the globally filtered data ---
    final_filtered_data_for_display = globally_filtered_data.copy()

    # Apply filters based on local filters now
    if local_domain_name_filter != 'All':
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['DOMAIN_NAME'] == local_domain_name_filter]
    if local_sub_domain_name_filter != 'All':
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['SUB_DOMAIN_NAME'] == local_sub_domain_name_filter]
    if local_db_filter != 'All':
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['DATABASE_NAME'] == local_db_filter]
    if local_schema_filter != 'All':
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['SCHEMA_NAME'] == local_schema_filter]
    if 'All' not in local_table_filter:
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['TABLE_NAME'].isin(local_table_filter)]
    if 'All' not in local_scheduling_state_filter:
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['LAST_REFRESH_HISTORY_COLLECTION_STATUS'].isin(local_scheduling_state_filter)]
    if 'All' not in local_target_lag_filter:
        local_target_lag_values_numeric = [int(s.replace('s', '')) for s in local_target_lag_filter]
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['TARGET_LAG_SEC'].isin(local_target_lag_values_numeric)]


    if final_filtered_data_for_display.empty:
        st.info("No tables match the combined global and local filter selections.", icon="ℹ️")
        return

    # Update tracking_data_df to be the final filtered one for KPIs and Charts
    tracking_data_df = final_filtered_data_for_display.copy()


    # --- 2. Overall Driver Health KPIs ---
    st.subheader("Overall Driver Health KPIs")
    kpi_cols = st.columns(4)

    latest_run = driver_history_df.iloc[0] if not driver_history_df.empty else None
    
    total_tables_tracked = tracking_data_df['QUALIFIED_NAME'].nunique() if not tracking_data_df.empty else 0
    active_rh_tracking = tracking_data_df[
        (tracking_data_df['IS_ACTIVE'] == True) & (tracking_data_df['TRACK_REFRESH_HISTORY'] == True)
    ].shape[0] if not tracking_data_df.empty else 0
    active_metadata_tracking = tracking_data_df[
        (tracking_data_df['IS_ACTIVE'] == True) & (tracking_data_df['TRACK_METADATA_SNAPSHOT'] == True)
    ].shape[0] if not tracking_data_df.empty else 0
    
    tables_not_refreshed_last_3_days = 0
    if not tracking_data_df.empty and 'LATEST_DATA_TIMESTAMP' in tracking_data_df.columns:
        three_days_ago = datetime.now() - timedelta(days=3)
        tables_not_refreshed_last_3_days = tracking_data_df[
            (tracking_data_df['LATEST_DATA_TIMESTAMP'].isna()) |
            (tracking_data_df['LATEST_DATA_TIMESTAMP'] < three_days_ago)
        ].shape[0]

    with kpi_cols[0]:
        st.metric("Total Tables Tracked", total_tables_tracked)
        st.metric("Active (RH) Tracking", active_rh_tracking)
    with kpi_cols[1]:
        st.metric("Active Tables Monitored", total_tables_tracked)
        st.metric("Active (Metadata) Tracking", active_metadata_tracking)
    with kpi_cols[2]:
        if latest_run is not None:
            st.metric("Last Driver Run Time", latest_run['RUN_END_TIME'].strftime('%Y-%m-%d %H:%M:%S'))
        else:
            st.metric("Last Driver Run Time", "N/A")
        st.metric("Tables Not Refreshed (last 3d)", tables_not_refreshed_last_3_days)
    with kpi_cols[3]:
        if latest_run is not None:
            duration_formatted = format_seconds_to_readable(
                pd.Series([latest_run['TOTAL_DURATION_SEC']]), "mixed"
            ).iloc[0]
            st.metric("Last Run Duration", duration_formatted)
        else:
            st.metric("Last Run Duration", "N/A")

    st.markdown("---")

    # --- 3. Driver Execution Time Trend Chart and Collection Status Distribution ---
    chart_row_cols = st.columns([0.6, 0.4])

    with chart_row_cols[0]: # Driver Execution Time Trend Chart (Left)
        st.subheader("Driver Execution Time Trend")
        st.write("Historical execution times of the main collection driver program.")
        if not driver_history_df.empty:
            driver_history_chart_data = driver_history_df.copy()
            driver_history_chart_data.rename(columns={
                'RUN_START_TIME': 'Run Time',
                'TOTAL_DURATION_SEC': 'Duration (seconds)'
            }, inplace=True)

            log_scale_y = st.checkbox("Log Scale Y-axis (Driver Trend)", value=False, key="log_scale_driver_trend")
            
            fig_trend = px.line(
                driver_history_chart_data,
                x='Run Time',
                y='Duration (seconds)',
                title='Driver Program Execution Duration Over Time',
                markers=True,
                log_y=log_scale_y
            )
            fig_trend.update_layout(hovermode="x unified")
            st.plotly_chart(fig_trend, use_container_width=True)
        else:
            st.info("No historical driver execution data for trend chart.", icon="ℹ️")

    with chart_row_cols[1]: # Collection Status Distribution (Right)
        st.subheader("Collection Status Distribution")
        st.write("Breakdown of tables by their last collection status for each type.")
        if not tracking_data_df.empty:
            rh_status_counts = tracking_data_df['LAST_REFRESH_HISTORY_COLLECTION_STATUS'].value_counts().reset_index()
            rh_status_counts.columns = ['Status', 'Count']
            rh_status_counts['Collection Type'] = 'Refresh History'

            md_status_counts = tracking_data_df['LAST_METADATA_COLLECTION_STATUS'].value_counts().reset_index()
            md_status_counts.columns = ['Status', 'Count']
            md_status_counts['Collection Type'] = 'Metadata Snapshot'

            combined_status_counts = pd.concat([rh_status_counts, md_status_counts])

            status_color_map_for_chart = {
                'SUCCESS': 'green',
                'SUCCESS_NO_RECORDS': 'lightgreen',
                'FAILED': 'red',
                'FAILED_EXECUTION': 'red',
                'FAILED_INPUT': 'red',
                'FAILED_SUBMISSION': 'red',
                'SUSPENDED': 'orange',
                'UNKNOWN': 'gray',
                'N/A': 'lightgray'
            }

            fig_bar = px.bar(
                combined_status_counts,
                x='Count',
                y='Collection Type',
                color='Status',
                orientation='h',
                title='Last Collection Status by Type',
                color_discrete_map=status_color_map_for_chart,
                text='Count'
            )
            fig_bar.update_traces(textposition='outside')
            fig_bar.update_layout(showlegend=True, yaxis_title=None, xaxis_title='Number of Tables')
            st.plotly_chart(fig_bar, use_container_width=True)
        else:
            st.info("No detailed tracking data for status distribution.", icon="ℹ️")
    
    st.markdown("---")

    # --- 4. Detailed Collection Status per Table (with local filtering) ---
    st.subheader("Detailed Collection Status per Table")
    st.write("View the last collection attempt status and messages for each dynamic table being tracked.")

    # Local filter options are derived from the already globally-filtered tracking_data_df
    # Note: `tracking_data_df` here is already filtered by global filters.
    # Pass it as `all_data_for_options` to `render_dynamic_filters_local`.
    if tracking_data_df.empty:
        st.info("No detailed collection status per table available.", icon="ℹ️")
        return

    # Initialize local filter states (using a distinct prefix like 'dt_health_tab_')
    # This must happen before render_dynamic_filters_local
    if 'dt_health_tab_domain_name' not in st.session_state: st.session_state.dt_health_tab_domain_name = 'All'
    if 'dt_health_tab_sub_domain_name' not in st.session_state: st.session_state.dt_health_tab_sub_domain_name = 'All'
    if 'dt_health_tab_db_filter' not in st.session_state: st.session_state.dt_health_tab_db_filter = 'All'
    if 'dt_health_tab_schema_filter' not in st.session_state: st.session_state.dt_health_tab_schema_filter = 'All'
    if 'dt_health_tab_table_filter' not in st.session_state: st.session_state.dt_health_tab_table_filter = ['All']
    if 'dt_health_tab_scheduling_state_filter' not in st.session_state: st.session_state.dt_health_tab_scheduling_state_filter = ['All']
    if 'dt_health_tab_target_lag' not in st.session_state: st.session_state.dt_health_tab_target_lag = ['All']
    if 'dt_health_tab_display_lag_times_in' not in st.session_state: st.session_state.dt_health_tab_display_lag_times_in = 'mixed'


    # Call render_dynamic_filters_local for the local filters on this tab
    # It returns a dict of the current selections for local filters
    current_local_filters_state = render_dynamic_filters_local(tracking_data_df, filter_prefix="dt_health_tab_")
    
    # Extract local filter values from the returned dict to apply to DataFrame
    local_domain_name_filter = current_local_filters_state['domain_name']
    local_sub_domain_name_filter = current_local_filters_state['sub_domain_name']
    local_db_filter = current_local_filters_state['database']
    local_schema_filter = current_local_filters_state['schema']
    local_table_filter = current_local_filters_state['table_name']
    local_scheduling_state_filter = current_local_filters_state['scheduling_state']
    local_target_lag_filter = current_local_filters_state['target_lag']
    local_display_lag_times_in = current_local_filters_state['display_lag_times_in']


    # --- Apply LOCAL filters to the globally filtered data ---
    final_filtered_data_for_display = tracking_data_df.copy() # Start from the globally filtered base

    if local_domain_name_filter != 'All':
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['DOMAIN_NAME'] == local_domain_name_filter]
    if local_sub_domain_name_filter != 'All':
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['SUB_DOMAIN_NAME'] == local_sub_domain_name_filter]
    if local_db_filter != 'All':
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['DATABASE_NAME'] == local_db_filter]
    if local_schema_filter != 'All':
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['SCHEMA_NAME'] == local_schema_filter]
    if 'All' not in local_table_filter:
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['TABLE_NAME'].isin(local_table_filter)]
    if 'All' not in local_scheduling_state_filter:
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['LAST_REFRESH_HISTORY_COLLECTION_STATUS'].isin(local_scheduling_state_filter)]
    if 'All' not in local_target_lag_filter:
        local_target_lag_values_numeric = [int(s.replace('s', '')) for s in local_target_lag_filter]
        final_filtered_data_for_display = final_filtered_data_for_display[final_filtered_data_for_display['TARGET_LAG_SEC'].isin(local_target_lag_values_numeric)]


    if final_filtered_data_for_display.empty:
        st.info("No tables match the combined global and local filter selections.", icon="ℹ️")
        return

    # Update tracking_data_df to be the final filtered one for KPIs and Charts
    tracking_data_df = final_filtered_data_for_display.copy()


    # ... (KPIs section - uses the new `tracking_data_df` and `current_display_lag_times_in_local`) ...
    # ... (Charts section - uses the new `tracking_data_df` and `current_display_lag_times_in_local`) ...

    # Detailed Table section - uses the new `tracking_data_df` and `current_display_lag_times_in_local`
    display_df = tracking_data_df.copy()

    # Apply time formatting here based on current_display_lag_times_in_local
    if 'MEAN_LAG_SEC' in display_df.columns:
        display_df['MEAN_LAG_SEC_FMT'] = format_seconds_to_readable(display_df['MEAN_LAG_SEC'], current_display_lag_times_in_local)
    if 'MAXIMUM_LAG_SEC' in display_df.columns:
        display_df['MAXIMUM_LAG_SEC_FMT'] = format_seconds_to_readable(display_df['MAXIMUM_LAG_SEC'], current_display_lag_times_in_local)
    if 'TARGET_LAG_SEC' in display_df.columns:
        display_df['TARGET_LAG_SEC_FMT'] = format_seconds_to_readable(display_df['TARGET_LAG_SEC'], current_display_lag_times_in_local)


    display_df['LAST_RH_COLLECT_TIME'] = display_df['LAST_REFRESH_HISTORY_COLLECTION_TIMESTAMP'].dt.strftime('%Y-%m-%d %H:%M:%S')
    display_df['LAST_MD_COLLECT_TIME'] = display_df['LAST_METADATA_COLLECTION_TIMESTAMP'].dt.strftime('%Y-%m-%d %H:%M:%S')
    display_df['LATEST_DATA_TIMESTAMP_FMT'] = display_df['LATEST_DATA_TIMESTAMP'].dt.strftime('%Y-%m-%d %H:%M:%S')
    display_df['TRACKING_RECORD_LAST_UPDATED'] = display_df['UPDATED_AT'].dt.strftime('%Y-%m-%d %H:%M:%S')

    display_df = display_df.drop(columns=[
        'LAST_REFRESH_HISTORY_COLLECTION_MESSAGE', 
        'LAST_METADATA_COLLECTION_MESSAGE'
    ], errors='ignore') 

    display_df = display_df.rename(columns={
        'QUALIFIED_NAME': 'Dynamic Table',
        'IS_ACTIVE': 'Active?',
        'TRACK_REFRESH_HISTORY': 'Track RH?',
        'LAST_REFRESH_HISTORY_COLLECTION_STATUS': 'Last RH Status',
        'TRACK_METADATA_SNAPSHOT': 'Track Metadata?',
        'LAST_METADATA_COLLECTION_STATUS': 'Last Metadata Status',
        'LAST_RH_COLLECT_TIME': 'Last RH Collect Time',
        'LAST_MD_COLLECT_TIME': 'Last Metadata Collect Time',
        'LATEST_DATA_TIMESTAMP': 'Latest Data Time',
        'UPDATED_AT': 'Tracking Record Last Updated'
    })

    final_cols_order = [
        'Dynamic Table',
        'Active?',
        'Track RH?',
        'Last RH Collect Time',
        'Last RH Status',
        'Track Metadata?',
        'Last Metadata Collect Time',
        'Last Metadata Status',
        'Latest Data Time',
        'MEAN_LAG_SEC_FMT',
        'MAXIMUM_LAG_SEC_FMT',
        'TARGET_LAG_SEC_FMT',
        'Tracking Record Last Updated'
    ]

    final_display_df = display_df[[col for col in final_cols_order if col in display_df.columns]]

    st.dataframe(final_display_df, use_container_width=True)
