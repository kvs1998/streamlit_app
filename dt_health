# tabs/dt_health_tab.py (Modified to use dynamic filters, with correct local filtering)
import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta

# --- Helper functions (from previous code) ---
def format_seconds_to_readable(seconds_series, format_type):
    if not isinstance(seconds_series, pd.Series):
        seconds_series = pd.Series([seconds_series])
    numeric_series = pd.to_numeric(seconds_series, errors='coerce')
    if numeric_series.empty or pd.isna(numeric_series).all():
        return pd.Series(["N/A"] * len(numeric_series), index=numeric_series.index)
    def format_single_second(s, f_type):
        if pd.isna(s): return "N/A"
        s = float(s)
        if s == 0: return "0s"
        if f_type == "seconds": return f"{s:.1f}s"
        elif f_type == "minutes": return f"{(s / 60):.1f}m"
        elif f_type == "hours": return f"{(s / 3600):.1f}h"
        elif f_type == "days": return f"{(s / 86400):.1f}d"
        elif f_type == "mixed":
            days = int(s // 86400); s_remaining = s % 86400
            hours = int(s_remaining // 3600); s_remaining = s_remaining % 3600
            minutes = int(s_remaining // 60); seconds = s_remaining % 60
            parts = []
            if days > 0: parts.append(f"{days}d")
            if hours > 0: parts.append(f"{hours}h")
            if minutes > 0: parts.append(f"{minutes}m")
            if seconds > 0.1 and (not parts or seconds >= 1): parts.append(f"{seconds:.1f}s")
            return " ".join(parts) if parts else "0s"
        return str(s)
    return numeric_series.apply(lambda x: format_single_second(x, f_type=format_type))

# --- Data Fetching Functions ---

@st.cache_data(ttl=(12*60*60))
def fetch_driver_execution_history_summary():
    session = st.session_state.get_snowflake_session()
    AUDIT_LOG_TABLE_FQDN = "YOUR_DB.YOUR_SCHEMA.T_DT_COLLECTION_AUDIT_LOG"
    query = f"""
    SELECT
        DRIVER_RUN_UUID, RUN_STATUS, RUN_START_TIME, RUN_END_TIME,
        TOTAL_DURATION_SEC, TOTAL_TABLES_FOUND, TOTAL_JOBS_LAUNCHED,
        TOTAL_ASYNC_JOBS_SUCCEEDED, TOTAL_ASYNC_JOBS_FAILED,
        MESSAGE AS RUN_MESSAGE, TIMEZONE
    FROM {AUDIT_LOG_TABLE_FQDN}
    WHERE RUN_START_TIME >= DATEADD(day, -30, CURRENT_TIMESTAMP())
    ORDER BY RUN_START_TIME DESC
    """
    df = session.sql(query).to_pandas()
    if not df.empty:
        df['RUN_START_TIME'] = pd.to_datetime(df['RUN_START_TIME'])
        df['RUN_END_TIME'] = pd.to_datetime(df['RUN_END_TIME'])
    return df

@st.cache_data(ttl=(5*60))
def fetch_dt_tracking_data():
    session = st.session_state.get_snowflake_session()
    TRACKING_TABLE_FQDN = "YOUR_DB.YOUR_SCHEMA.T_DYNAMIC_TABLE_TRACKING"
    METADATA_SNAPSHOT_TABLE_FQDN = "YOUR_DB.YOUR_SCHEMA.T_DYNAMIC_TABLE_METADATA_LATEST_SNAPSHOT"

    query = f"""
    SELECT
        t.QUALIFIED_NAME,
        t.DATABASE_NAME,
        t.SCHEMA_NAME,
        t.TABLE_NAME,
        t.DOMAIN_NAME,
        t.SUB_DOMAIN_NAME,
        t.IS_ACTIVE,
        t.TRACK_REFRESH_HISTORY,
        t.LAST_REFRESH_HISTORY_COLLECTION_TIMESTAMP,
        t.LAST_REFRESH_HISTORY_COLLECTION_STATUS,
        t.LAST_REFRESH_HISTORY_COLLECTION_MESSAGE,
        t.TRACK_METADATA_SNAPSHOT,
        t.LAST_METADATA_COLLECTION_TIMESTAMP,
        t.LAST_METADATA_COLLECTION_STATUS,
        t.LAST_METADATA_COLLECTION_MESSAGE,
        ms.LATEST_DATA_TIMESTAMP,
        ms.MEAN_LAG_SEC,
        ms.MAXIMUM_LAG_SEC,
        ms.TARGET_LAG_SEC,
        t.UPDATED_AT
    FROM
        {TRACKING_TABLE_FQDN} AS t
    LEFT JOIN
        {METADATA_SNAPSHOT_TABLE_FQDN} AS ms
    ON
        t.QUALIFIED_NAME = ms.QUALIFIED_NAME
    ORDER BY
        t.QUALIFIED_NAME
    """
    df = session.sql(query).to_pandas()
    if not df.empty:
        df['LAST_REFRESH_HISTORY_COLLECTION_TIMESTAMP'] = pd.to_datetime(df['LAST_REFRESH_HISTORY_COLLECTION_TIMESTAMP'])
        df['LAST_METADATA_COLLECTION_TIMESTAMP'] = pd.to_datetime(df['LAST_METADATA_COLLECTION_TIMESTAMP'])
        df['LATEST_DATA_TIMESTAMP'] = pd.to_datetime(df['LATEST_DATA_TIMESTAMP'])
        df['UPDATED_AT'] = pd.to_datetime(df['UPDATED_AT'])
    return df


# --- Helper to manage widget state persistence for local filters ---
# These are identical to the ones in filter_canvas, but defined here for local context
def persist_local_widget_state(key_prefix):
    temp_key = f"_{key_prefix}"
    perm_key = key_prefix
    if temp_key in st.session_state:
        st.session_state[perm_key] = st.session_state[temp_key]

def load_local_widget_state(key_prefix, default_value):
    perm_key = key_prefix
    temp_key = f"_{key_prefix}"
    if perm_key not in st.session_state:
        st.session_state[perm_key] = default_value
    st.session_state[temp_key] = st.session_state[perm_key]
    return st.session_state[perm_key]

# --- Filter Definitions Map for Local Filters (using the same structure as global) ---
# NOTE: This defines the filters specific to THIS TAB.
# The keys should be unique to this tab (e.g., 'dt_health_tab_db_filter')
LOCAL_FILTER_DEFINITIONS = [
    {
        'id': 'domain_name',
        'label': "Domain Name:",
        'column_name': 'DOMAIN_NAME',
        'widget_type': 'selectbox',
        'default_value': 'All'
    },
    {
        'id': 'sub_domain_name',
        'label': "Sub Domain Name:",
        'column_name': 'SUB_DOMAIN_NAME',
        'widget_type': 'selectbox',
        'default_value': 'All',
        'depends_on': 'domain_name'
    },
    {
        'id': 'database',
        'label': "Database:",
        'column_name': 'DATABASE_NAME',
        'widget_type': 'selectbox',
        'default_value': 'All',
        'depends_on': 'sub_domain_name'
    },
    {
        'id': 'schema',
        'label': "Schema:",
        'column_name': 'SCHEMA_NAME',
        'widget_type': 'selectbox',
        'default_value': 'All',
        'depends_on': 'database'
    },
    {
        'id': 'table_name',
        'label': "Table(s):",
        'column_name': 'TABLE_NAME',
        'widget_type': 'multiselect',
        'default_value': ['All'],
        'depends_on': 'schema'
    },
    {
        'id': 'scheduling_state',
        'label': "Scheduling State(s):",
        'column_name': 'SCHEDULING_STATE_STATUS',
        'widget_type': 'multiselect',
        'default_value': ['All']
    },
    {
        'id': 'target_lag',
        'label': "Target Lag (seconds):",
        'column_name': 'TARGET_LAG_SEC_FMT', # Formatted for display
        'original_column_name': 'TARGET_LAG_SEC', # To filter by original numeric value
        'widget_type': 'multiselect',
        'default_value': ['All']
    }
]

# Separate filter definition for the independent radio button (Display Lag Times In)
LOCAL_RADIO_FILTER_DEFINITION = {
    'id': 'display_lag_times_in', # Note: This ID needs to be unique for this tab, or map to a global variable
    'label': "Display Lag Times In:",
    'options': ["mixed", "seconds", "minutes", "hours", "days"],
    'default_value': 'mixed'
}


def render_dynamic_filters_local(all_data_for_options: pd.DataFrame, filter_prefix: str = "dt_health_tab_"):
    """
    Renders a set of interdependent filter widgets for LOCAL use within a tab.
    Applies "parent takes priority" reset logic.
    
    Args:
        all_data_for_options (pd.DataFrame): The full DataFrame of data to derive filter options from.
        filter_prefix (str): Prefix for session state keys (e.g., 'dt_health_tab_').
    
    Returns:
        dict: The current selections from all local filters.
    """
    
    # --- Initialize Column Layouts ---
    # Row 1: Domain Name, Sub Domain Name, Database, Schema
    cols_row1 = st.columns(4) 
    # Row 2: Table(s), Scheduling State(s), Target Lag (seconds), Display Lag Times In
    cols_row2 = st.columns(4) 
    # Note: 'is_active' filter is not explicitly in this local layout, assuming it's only global.

    # Map filter IDs to specific Streamlit column objects based on desired layout
    col_map = {
        'domain_name': cols_row1[0],
        'sub_domain_name': cols_row1[1],
        'database': cols_row1[2],
        'schema': cols_row1[3],

        'table_name': cols_row2[0],
        'scheduling_state': cols_row2[1],
        'target_lag': cols_row2[2],
        'display_lag_times_in': cols_row2[3] # Display Lag Times In (radio button)
    }

    # This DataFrame will be progressively filtered as we determine options for cascading widgets.
    filtered_df_for_options_cascade = all_data_for_options.copy() 

    # --- Step-by-step processing of filters based on dependency for option generation ---
    # Process the parent-child chain first regardless of final visual layout order.
    # The order in LOCAL_FILTER_DEFINITIONS is crucial here.
    
    # Define a combined list of filters to iterate in logical dependency order
    # (Domain -> Sub Domain -> Database -> Schema -> Table)
    # followed by other independent ones.
    logical_filter_order = [
        fd for fd in LOCAL_FILTER_DEFINITIONS if fd['id'] in ['domain_name', 'sub_domain_name', 'database', 'schema', 'table_name']
    ]
    # Add other independent filters, which will derive options from the *initial* all_data_for_options
    # and don't affect `filtered_df_for_options_cascade`
    independent_filters = [
        fd for fd in LOCAL_FILTER_DEFINITIONS if fd['id'] not in ['domain_name', 'sub_domain_name', 'database', 'schema', 'table_name']
    ]

    # Process cascading filters first
    for f_def in logical_filter_order:
        current_filter_session_key = f"{filter_prefix}{f_def['id']}"
        
        # Determine options for THIS widget based on its parent's CURRENT state in `filtered_df_for_options_cascade`
        # Note: filtered_df_for_options_cascade is updated by parent filters in *this loop*.
        
        options_list_for_widget = []
        # Get unique options for the current filter's column from `filtered_df_for_options_cascade`
        options_from_df = filtered_df_for_options_cascade[f_def['column_name']].dropna().unique().tolist()
        options_list_for_widget = ['All'] + sorted(options_from_df)

        # Determine the initial selection for the widget (applying "parent takes priority" reset)
        current_stored_value = st.session_state.get(current_filter_session_key, f_def['default_value'])

        if f_def['widget_type'] == 'selectbox':
            if current_stored_value not in options_list_for_widget:
                current_stored_value = f_def['default_value']
                st.session_state[current_filter_session_key] = current_stored_value
            widget_index = options_list_for_widget.index(current_stored_value)
            
            with col_map[f_def['id']]:
                selected_value_from_widget = st.selectbox(
                    f_def['label'],
                    options=options_list_for_widget,
                    key=current_filter_session_key,
                    index=widget_index
                )

        elif f_def['widget_type'] == 'multiselect':
            valid_selections = [v for v in current_stored_value if v in options_list_for_widget]
            if not valid_selections and f_def['default_value'] == ['All'] and 'All' in options_list_for_widget:
                valid_selections = ['All']
            elif not valid_selections:
                valid_selections = []
            
            # Update session state with the chosen valid selection
            st.session_state[current_filter_session_key] = valid_selections

            with col_map[f_def['id']]:
                selected_value_from_widget = st.multiselect(
                    f_def['label'],
                    options=options_list_for_widget,
                    key=current_filter_session_key,
                    default=valid_selections
                )
        
        # After processing this widget, filter `filtered_df_for_options_cascade` further
        # for the options of the NEXT dependent widget in the logical chain.
        current_selection_for_filter = st.session_state[current_filter_session_key]
        if f_def['id'] in ['domain_name', 'sub_domain_name', 'database', 'schema']: # These are the parent filters
            if current_selection_for_filter != 'All':
                filtered_df_for_options_cascade = filtered_df_for_options_cascade[filtered_df_for_options_cascade[f_def['column_name']] == current_selection_for_filter]

    # Process independent filters
    for f_def in independent_filters:
        current_filter_session_key = f"{filter_prefix}{f_def['id']}"
        
        options_list_for_widget = []
        if 'options_override' in f_def:
            options_list_for_widget = f_def['options_override']
        else:
            options_from_df = all_data_for_options[f_def['column_name']].dropna().unique().tolist()
            if f_def['column_name'] == 'IS_ACTIVE':
                options_list_for_widget = ['All'] + options_from_df
            else:
                options_list_for_widget = ['All'] + sorted(options_from_df)
        
        current_stored_value = st.session_state.get(current_filter_session_key, f_def['default_value'])
        
        with col_map[f_def['id']]:
            if f_def['widget_type'] == 'selectbox':
                if current_stored_value not in options_list_for_widget:
                    current_stored_value = f_def['default_value']
                    st.session_state[current_filter_session_key] = current_stored_value
                widget_index = options_list_for_widget.index(current_stored_value)
                st.selectbox(f_def['label'], options=options_list_for_widget, key=current_filter_session_key, index=widget_index)
            elif f_def['widget_type'] == 'multiselect':
                valid_selections = [v for v in current_stored_value if v in options_list_for_widget]
                if not valid_selections and f_def['default_value'] == ['All'] and 'All' in options_list_for_widget:
                    valid_selections = ['All']
                elif not valid_selections:
                    valid_selections = []
                st.session_state[current_filter_session_key] = valid_selections
                st.multiselect(f_def['label'], options=options_list_for_widget, key=current_filter_session_key, default=valid_selections)
    
    # --- Render the independent radio button (Display Lag Times In) ---
    radio_f_def = LOCAL_RADIO_FILTER_DEFINITION
    current_radio_value = st.session_state.get(radio_f_def['id'], radio_f_def['default_value'])
    radio_options_list = radio_f_def['options']
    if current_radio_value not in radio_options_list:
        current_radio_value = radio_f_def['default_value']
        st.session_state[radio_f_def['id']] = current_radio_value
    radio_index = radio_options_list.index(current_radio_value)

    with col_map[radio_f_def['id']]:
        st.radio(
            radio_f_def['label'],
            options=radio_options_list,
            key=radio_f_def['id'],
            index=radio_index,
            horizontal=True
        )

    # Return the collected selections (from the permanent session state keys)
    # This dictionary aggregates the current state of all filters
    final_filters_state = {}
    for f_def in FILTER_DEFINITIONS:
        final_filters_state[f_def['id']] = st.session_state[f"{filter_prefix}{f_def['id']}"]
    final_filters_state[LOCAL_RADIO_FILTER_DEFINITION['id']] = st.session_state[LOCAL_RADIO_FILTER_DEFINITION['id']]
    
    return final_filters_state # Returns the dict of active filters


def render_filter_canvas_tab():
    st.header("Global Filter Canvas")
    st.write("Set high-level filters here to apply across all relevant dashboard tabs. Each dashboard tab can apply further refinements.")

    # --- Initialize session state for ALL global filter keys ---
    # These will use a "global_" prefix in their session_state keys
    # Initialize all potential local filter states first.
    if 'global_domain_name' not in st.session_state: st.session_state.global_domain_name = 'All'
    if 'global_sub_domain_name' not in st.session_state: st.session_state.global_sub_domain_name = 'All'
    if 'global_db_filter' not in st.session_state: st.session_state.global_db_filter = 'All'
    if 'global_schema_filter' not in st.session_state: st.session_state.global_schema_filter = 'All'
    if 'global_table_filter' not in st.session_state: st.session_state.global_table_filter = ['All']
    if 'global_scheduling_state_filter' not in st.session_state: st.session_state.global_scheduling_state_filter = ['All']
    if 'global_target_lag' not in st.session_state: st.session_state.global_target_lag = ['All']
    if 'global_is_active_filter' not in st.session_state: st.session_state.global_is_active_filter = 'All'
    # The radio button state will also be managed globally if filter_canvas is used as the master
    if 'display_lag_times_in' not in st.session_state: st.session_state.display_lag_times_in = 'mixed'


    all_options_data = get_all_filter_options_data()
    if all_options_data.empty:
        st.info("No data available to populate filters. Please check the tracking table.", icon="ℹ️")
        return

    st.markdown("---")
    st.subheader("Master Filters")

    # Call the dynamic filter renderer for global filters
    # It returns a dict of the current selections
    current_global_filters_state = render_dynamic_filters(all_options_data, filter_prefix="global_")

    st.markdown("---")
    st.info("These filters will be automatically applied as a first level of filtering on relevant dashboard tabs.", icon="ℹ️")

    # Optional: Display current global filters for debugging/confirmation
    # st.json(current_global_filters_state)

# End of tabs/filter_canvas.py
